\section{Loss functions for multiple annotators}

As mentioned in Section \ref{ch:dl_seg}, a loss function is a key element
for defining the objective function of a deep learning model. The
categorical cross-entropy loss is a common loss function for
classification tasks. However, in the case of multiple annotators,
the categorical cross-entropy loss is not able to handle the varying
reliability of the annotators. In this section, we will propose a
loss function that is able to handle multiple annotators'
segmentation masks while accounting for their varying reliability
across different regions of the image.
\subsection{Generalized Cross Entropy}

The \gls{GCE} loss function was first introduced by
\cite{ZhangEtAl2018} as a robust alternative to the standard
cross-entropy loss, particularly effective in handling noisy labels.
Let us first consider the \gls{CE} and \gls{MAE} loss functions:

\begin{equation}
  MAE(\mathbf{y}, f(\mathbf{x})) = \|\mathbf{y} - f(\mathbf{x})\|_1
\end{equation}

\begin{equation}
  CE(\mathbf{y}, f(\mathbf{x})) = \sum_{k=1}^K y_k \log(f_k(\mathbf{x}))
\end{equation}

where $y_k \in \mathbf{y}$, $f_k(\mathbf{x}) \in f(\mathbf{x})$, and
$\|\cdot\|_1$ stands for the $l_1$-norm. Of note,
$\mathbf{1}^\top\mathbf{y} = \mathbf{1}^\top f(\mathbf{x}) = 1$,
$\mathbf{1} \in \{1\}^K$ being an all-ones vector. In addition, the
MAE loss can be rewritten for softmax outputs, yielding:

\begin{equation}
  MAE(\mathbf{y}, f(\mathbf{x})) = 2(1 - \mathbf{1}^\top(\mathbf{y}
  \odot f(\mathbf{x})))
\end{equation}

where $\odot$ stands for the element-wise product.

The \gls{CE} is characterized by the following properties:

\begin{itemize}
  \item It is unbounded from above.
  \item It heavily penalizes confident but wrong predictions.
  \item It is more sensitive to noisy labels.
\end{itemize}

On the other hand, the \gls{MAE} is characterized by the following properties:

\begin{itemize}
  \item It is bounded and more robust to outliers.
  \item It assigns equal weights to all mistakes regardless of confidence.
  \item It is symmetric in softmax based representations.
  \item It is more robust to noisy labels but slower to train.
\end{itemize}

The GCE loss function is defined by the authors in \cite{ZhangEtAl2018} as:

\begin{equation}
  GCE(\mathbf{y}, f(\mathbf{x})) = 2\frac{1 -
  (\mathbf{1}^\top(\mathbf{y} \odot f(\mathbf{x})))^q}{q},
\end{equation}

with $q \in (0,1]$. Remarkably, the limiting case for $q \to 0$ in
GCE is equivalent to the CE expression, and when $q = 1$, it equals
the MAE loss. In addition, the GCE holds the following gradient with
regard to $\theta$:

\begin{equation}
  \frac{\partial GCE(\mathbf{y}, f(\mathbf{x};\theta)|k)}{\partial
  \theta} = -f_k(\mathbf{x};\theta)^{q-1}\nabla_\theta f_k(\mathbf{x};\theta).
\end{equation}

The GCE loss exhibits several desirable properties:

\begin{itemize}
  \item It is more robust to label noise compared to standard cross-entropy
  \item The truncation parameter $q$ allows for controlling the
    sensitivity to outliers
  \item It preserves the convexity property for optimization
\end{itemize}

\subsection{Extension to Multiple Annotators}

In the context of multiple annotators, we need to consider the
varying reliability of each annotator across different regions of the
image. Let's consider a $k$-class multiple annotators segmentation
problem with the following data representation:

\begin{equation}
  \mathbf X \in \mathbb{R}^{W \times H}, \{ \mathbf Y_r \in
  \{0,1\}^{W \times H \times K} \}_{r=1}^R; \;\; \mathbf {\hat Y} \in
  [0,1]^{W\times H \times K} = f(\mathbf X)
\end{equation}

where the segmentation mask function maps the input to output as:

\begin{equation}
  f: \mathbb  R ^{W\times H} \to [0,1]^{W\times H\times K}
\end{equation}

The segmentation masks $\mathbf Y_r$ satisfy the following condition
for being a softmax-like representation:

\begin{equation}
  \mathbf Y_r[w,h,:] \mathbf{1} ^ \top _ k = 1; \;\; w \in W, h \in H
\end{equation}

\subsection{Reliability Maps and Truncated GCE}

The key innovation in our approach is the introduction of reliability
maps $\Lambda_r$ for each annotator:

\begin{equation}
  \bigg\{ \Lambda_r (\mathbf X; \theta ) \in [0,1] ^{W\times H} \bigg\}_{r=1}^R
\end{equation}

These reliability maps estimate the confidence of each annotator at
every spatial location $(w,h)$ in the image. The maps are learned
jointly with the segmentation model, allowing the network to:

\begin{itemize}
  \item Weight the contribution of each annotator differently across the image
  \item Adapt to varying levels of expertise in different regions
  \item Handle cases where annotators might be more reliable in
    certain areas than others
\end{itemize}

The proposed Truncated Generalized Cross Entropy for Semantic
Segmentation (TGCE$_{SS}$) combines the robustness of GCE with the
flexibility of reliability maps:

\begin{equation}
  \begin{split}
    TGCE_{SS}(\mathbf{Y}_r,f(\mathbf X;\theta) | \mathbf{\Lambda}_r
    (\mathbf X;\theta)) = \mathbb E_{r} \Bigg\{ \mathbb E_{w,h}
      \Bigg\{ \Lambda_r (\mathbf X; \theta) \circ \mathbb E_k \bigg\{
          \mathbf Y_r \circ \bigg( \frac{\mathbf 1 _{W\times H \times
        K} - f(\mathbf X;\theta) ^{\circ q }}{q} \bigg); k \in K  \bigg\}  + \\
        \left(\mathbf 1 _{W \times H } - \Lambda _r (\mathbf
        X;\theta)\right) \circ \bigg(   \frac{\mathbf 1_{W\times H} -
        (\frac {1}{k} \mathbf 1_{W\times H})^{\circ q}}{q} \bigg); w \in
    W, h \in H \Bigg\};r\in R\Bigg\}
  \end{split}
\end{equation}

where $q \in (0,1)$ controls the truncation level. The loss function
consists of two main components:

\begin{itemize}
  \item The first term weighted by $\Lambda_r$ represents the GCE
    loss for regions where the annotator is considered reliable
  \item The second term weighted by $(1-\Lambda_r)$ provides a
    uniform prior for regions where the annotator is considered unreliable
\end{itemize}

For a batch containing $N$ samples, the total loss is computed as:

\begin{equation}
  \mathscr{L}\left(\mathbf{Y}_r[n],f(\mathbf X[n];\theta) |
  \mathbf{\Lambda}_r (\mathbf X[n];\theta)\right)  = \frac{1}{N}
  \sum_{n}^N TGCE_{SS}(\mathbf{Y}_r[n],f(\mathbf X[n];\theta) |
  \mathbf{\Lambda}_r (\mathbf X[n];\theta))
\end{equation}

\section{Proposed Model}

Our proposed model architecture combines the strengths of UNET with a
ResNet-34 backbone, specifically designed to work with the
TGCE$_{SS}$ loss function. The architecture is illustrated in Figure
\ref{fig:model_architecture}.

\subsection{Backbone Architecture}

The model employs a pre-trained ResNet-34 as its encoder backbone,
leveraging its deep residual learning framework for efficient feature
extraction. The choice of ResNet-34 provides several key advantages:
efficient feature extraction through residual connections,
pre-trained weights that capture rich visual representations, and
stable gradient flow during training. We modify the ResNet-34
backbone to serve as the encoder in our UNET architecture by removing
the final fully connected layer and utilizing the feature maps from
different stages of the network for skip connections.

\subsection{UNET Architecture}

The UNET architecture follows a traditional encoder-decoder structure
with skip connections, where the encoder path implements the
ResNet-34 structure. The decoder path employs transposed convolutions
for upsampling, creating a symmetrical architecture that effectively
captures both high-level and low-level features. The architecture
incorporates four downsampling stages in the encoder, corresponding
to the ResNet-34 blocks, and four upsampling stages in the decoder.
These stages are connected through skip connections that bridge
corresponding encoder and decoder stages, allowing the network to
preserve fine-grained details. Each convolution operation is followed
by batch normalization and ReLU activation to ensure stable training
and effective feature learning.

\subsection{Reliability Map Branch}

A key innovation in our architecture is the parallel branch dedicated
to estimating reliability maps. This branch processes the same
encoder features as the main segmentation path but focuses on
learning the confidence of each annotator. Through a series of $1
\times 1$ convolutions, the branch reduces channel dimensions while
maintaining spatial information. The final output consists of $R$
reliability maps $\Lambda_r$, one for each annotator, with values
constrained to the $[0,1]$ range through a sigmoid activation
function. This design allows the network to learn and adapt to the
varying reliability of different annotators across different regions
of the image.

\subsection{Integration with TGCE$_{SS}$ Loss}

The model produces two distinct outputs: segmentation masks
$\mathbf{\hat{Y}} = f(\mathbf{X};\theta)$ and reliability maps
$\{\Lambda_r(\mathbf{X};\theta)\}_{r=1}^R$. These outputs work in
tandem with the TGCE$_{SS}$ loss function described in Section
\ref{sec:proposed_loss}. The loss function simultaneously guides the
learning of both the segmentation masks and reliability maps,
ensuring that the model learns to balance the contributions of
different annotators based on their estimated reliability.

\subsection{Training Process}

The training process begins with the initialization of the ResNet-34
backbone using pre-trained weights, providing a strong foundation for
feature extraction. The entire network is then trained end-to-end
using the Adam optimizer with a learning rate of $10^{-4}$. The
TGCE$_{SS}$ loss function plays a crucial role in updating both the
segmentation and reliability branches, ensuring that the model learns
to effectively handle multiple annotators' inputs while accounting
for their varying reliability.

The model's architecture is specifically designed to address the
challenges of multi-annotator segmentation. Through the ResNet-34
backbone, it learns robust segmentation features that capture
high-level patterns in the data. The UNET's skip connections enable
the preservation of fine-grained details, while the parallel
reliability branch allows the model to adapt to annotator-specific
characteristics. This comprehensive design enables the model to
effectively handle multiple annotators' inputs while maintaining high
segmentation accuracy and reliability estimation.
